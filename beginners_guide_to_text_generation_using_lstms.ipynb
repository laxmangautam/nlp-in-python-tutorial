{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "beginners-guide-to-text-generation-using-lstms.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EyHIpVTdxC8W",
        "TPYKgL9FxC8c"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmangautam/nlp-in-python-tutorial/blob/master/beginners_guide_to_text_generation_using_lstms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e084e610-8128-4769-ab64-6aa194044892",
        "_uuid": "20c011dd401be7b6448c43f965e5d0bf548c53b9",
        "id": "oZ8HaWRjxC7v"
      },
      "source": [
        "# Beginners Guide to Text Generation using LSTMs\n",
        "\n",
        "Text Generation is a type of Language Modelling problem. Language Modelling is the core problem for a number of of natural language processing tasks such as speech to text, conversational system, and text summarization. A trained language model learns the likelihood of occurrence of a word based on the previous sequence of words used in the text. Language models can be operated at character level, n-gram level, sentence level or even paragraph level. In this notebook, I will explain how to create a language model for generating natural language text by implement and training state-of-the-art Recurrent Neural Network. \n",
        "\n",
        "### Generating News headlines \n",
        "\n",
        "In this kernel, I will be using the dataset of [New York Times Comments and Headlines](https://www.kaggle.com/aashita/nyt-comments) to train a text generation language model which can be used to generate News Headlines\n",
        "\n",
        "\n",
        "## 1. Import the libraries\n",
        "\n",
        "As the first step, we need to import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "kXhqtCDnxC7w"
      },
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout , Activation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "from keras.optimizers import RMSprop\n",
        " \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        " \n",
        "import random\n",
        "import heapq\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs9CcEuBxC72",
        "outputId": "b475d4b9-be41-4d26-8bfd-37674ad07d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysRFFCiD1HEy",
        "outputId": "a9f711e9-9687-41c7-b535-6df5f1edb368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = open('/content/drive/My Drive/Colab Notebooks/Dataset_RNN_shakespeare.txt', \"r\").read()\n",
        " \n",
        "text = data.lower()\n",
        "print(text)\n",
        " \n",
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt \n",
        " \n",
        "text  = clean_text(text);\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3CCcgNH2xQo",
        "outputId": "dcb6c33a-7d23-4278-fa56-03478be35fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " \n",
        "characters = sorted(list(set(text)))\n",
        " \n",
        "print('corpus length:', len(text))\n",
        " \n",
        "print('total chars:', len(characters))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 5219164\n",
            "total chars: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTdBvcDH2UZf",
        "outputId": "ea6f9fd0-56a7-40ff-8a87-ef29820f6840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "char2indices = dict((c, i) for i, c in enumerate(characters))\n",
        " \n",
        "indices2char = dict((i, c) for i, c in enumerate(characters))\n",
        "print(char2indices)\n",
        " \n",
        "print(indices2char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37}\n",
            "{0: '\\n', 1: ' ', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9', 12: 'a', 13: 'b', 14: 'c', 15: 'd', 16: 'e', 17: 'f', 18: 'g', 19: 'h', 20: 'i', 21: 'j', 22: 'k', 23: 'l', 24: 'm', 25: 'n', 26: 'o', 27: 'p', 28: 'q', 29: 'r', 30: 's', 31: 't', 32: 'u', 33: 'v', 34: 'w', 35: 'x', 36: 'y', 37: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js7ugbZd3X00",
        "outputId": "f2b83545-2bca-4c5c-a09b-52c04fbdd678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        " \n",
        "maxlen = 40\n",
        " \n",
        "step = 3\n",
        "sentences = []\n",
        " \n",
        "next_chars = []\n",
        " \n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        " \n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 1739708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd7UDL8h3ssL"
      },
      "source": [
        "# Converting indices into vectorized format\n",
        " \n",
        "X = np.zeros((len(sentences), maxlen, len(characters)), dtype=np.bool)\n",
        " \n",
        "y = np.zeros((len(sentences), len(characters)), dtype=np.bool)\n",
        " \n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    X[i, t, char2indices[char]] = 1\n",
        "    y[i, char2indices[next_chars[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNXIqJ1r4M8w",
        "outputId": "35c31181-5594-4878-bc1a-872640f5955a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Model Building\n",
        " \n",
        "model = Sequential()\n",
        " \n",
        "model.add(LSTM(64, input_shape=(maxlen, len(characters))))\n",
        " \n",
        "model.add(Dense(len(characters)))\n",
        " \n",
        "model.add(Activation('softmax'))\n",
        " \n",
        " \n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
        " \n",
        "print (model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 64)                26368     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 38)                2470      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 38)                0         \n",
            "=================================================================\n",
            "Total params: 28,838\n",
            "Trainable params: 28,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PqfivS4TT4"
      },
      "source": [
        "# Function to convert prediction into index\n",
        " \n",
        "def pred_indices(preds, metric=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / metric\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds/np.sum(exp_preds)\n",
        "  probs = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "  return np.argmax(probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvZhHdvDGakR",
        "outputId": "594c7921-b8b3-41e1-dc0f-8e7f986d6fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "weigh= model.get_weights();    \n",
        "pklfile= \"modelweights.pkl\"\n",
        "fpkl= open(pklfile, 'wb')    #Python 3     \n",
        "pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "fpkl.close()\n",
        "\n",
        "\n",
        "sys.stdout.write(\"Test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EoGKfJdY_3D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCA6P0rz4aqp",
        "outputId": "3b4de585-118f-4a5b-827f-1437e1f26c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train and Evaluate the Model\n",
        " \n",
        "for iteration in range(1, 15):\n",
        "  print('-' * 40) \n",
        "  print('Iteration', iteration)\n",
        "  model.fit(X, y,batch_size=128,epochs=1)\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  for diversity in [0.2, 0.7,1.2]:\n",
        "    print('n----- diversity:', diversity)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"\\n')\n",
        "    print(str(iteration)  + \" Round completed  model training is completed \")\n",
        "    #sys.stdout.write(generated)\n",
        "    for i in range(400):\n",
        "      x = np.zeros((1, maxlen, len(characters)))\n",
        "      for t, char in enumerate(sentence):\n",
        "        x[0, t, char2indices[char]] = 1.\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = pred_indices(preds, diversity)\n",
        "        pred_char = indices2char[next_index]\n",
        "        generated += pred_char\n",
        "        sentence = sentence[1:] + pred_char\n",
        "        #sys.stdout.write(pred_char)\n",
        "        #sys.stdout.flush()\n",
        "        \n",
        "    weigh= model.get_weights();    \n",
        "    pklfile= \"modelweights.pkl\"\n",
        "    fpkl= open(pklfile, 'wb')    #Python 3     \n",
        "    pickle.dump(weigh, fpkl, protocol= pickle.HIGHEST_PROTOCOL)\n",
        "    fpkl.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Iteration 1\n",
            "13592/13592 [==============================] - 534s 39ms/step - loss: 1.6080\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"m\n",
            "    so much i love his heart but i per\"\n",
            "\n",
            "1 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"m\n",
            "    so much i love his heart but i per\"\n",
            "\n",
            "1 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"m\n",
            "    so much i love his heart but i per\"\n",
            "\n",
            "1 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 2\n",
            "13592/13592 [==============================] - 552s 41ms/step - loss: 1.4952\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"uld be so rich for when rich villains ha\"\n",
            "\n",
            "2 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"uld be so rich for when rich villains ha\"\n",
            "\n",
            "2 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"uld be so rich for when rich villains ha\"\n",
            "\n",
            "2 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 3\n",
            "13592/13592 [==============================] - 555s 41ms/step - loss: 1.4760\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"fought at holmedon thus\n",
            "    i never had \"\n",
            "\n",
            "3 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"fought at holmedon thus\n",
            "    i never had \"\n",
            "\n",
            "3 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"fought at holmedon thus\n",
            "    i never had \"\n",
            "\n",
            "3 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 4\n",
            "13592/13592 [==============================] - 557s 41ms/step - loss: 1.4663\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \" i can change these poor accoutrements\n",
            " \"\n",
            "\n",
            "4 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \" i can change these poor accoutrements\n",
            " \"\n",
            "\n",
            "4 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \" i can change these poor accoutrements\n",
            " \"\n",
            "\n",
            "4 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 5\n",
            "13592/13592 [==============================] - 564s 41ms/step - loss: 1.4635\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"other part of the plain\n",
            "\n",
            "enter hector\n",
            "\n",
            " \"\n",
            "\n",
            "5 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"other part of the plain\n",
            "\n",
            "enter hector\n",
            "\n",
            " \"\n",
            "\n",
            "5 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"other part of the plain\n",
            "\n",
            "enter hector\n",
            "\n",
            " \"\n",
            "\n",
            "5 Round completed  model training is completed \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Iteration 6\n",
            "13592/13592 [==============================] - 570s 42ms/step - loss: 1.4639\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"    exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scene ii\n",
            "before the duke \"\n",
            "\n",
            "6 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"    exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scene ii\n",
            "before the duke \"\n",
            "\n",
            "6 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"    exeunt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scene ii\n",
            "before the duke \"\n",
            "\n",
            "6 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 7\n",
            "13592/13592 [==============================] - 565s 42ms/step - loss: 1.4577\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"se are the tribunes of the people\n",
            "    th\"\n",
            "\n",
            "7 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"se are the tribunes of the people\n",
            "    th\"\n",
            "\n",
            "7 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"se are the tribunes of the people\n",
            "    th\"\n",
            "\n",
            "7 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 8\n",
            "13592/13592 [==============================] - 563s 41ms/step - loss: 1.4580\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"s father calld guiderius jove\n",
            "    when o\"\n",
            "\n",
            "8 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"s father calld guiderius jove\n",
            "    when o\"\n",
            "\n",
            "8 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"s father calld guiderius jove\n",
            "    when o\"\n",
            "\n",
            "8 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 9\n",
            "13592/13592 [==============================] - 571s 42ms/step - loss: 1.4680\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"not with such a cruel threatning look\n",
            "  \"\n",
            "\n",
            "9 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"not with such a cruel threatning look\n",
            "  \"\n",
            "\n",
            "9 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"not with such a cruel threatning look\n",
            "  \"\n",
            "\n",
            "9 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 10\n",
            "13592/13592 [==============================] - 562s 41ms/step - loss: 1.4781\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"                   enter caliban\n",
            "\n",
            "  cali\"\n",
            "\n",
            "10 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"                   enter caliban\n",
            "\n",
            "  cali\"\n",
            "\n",
            "10 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"                   enter caliban\n",
            "\n",
            "  cali\"\n",
            "\n",
            "10 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 11\n",
            "13592/13592 [==============================] - 560s 41ms/step - loss: 1.6257\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"\n",
            "\n",
            "\n",
            "scene ii\n",
            "the highway near gadshill\n",
            "\n",
            "e\"\n",
            "\n",
            "11 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"\n",
            "\n",
            "\n",
            "scene ii\n",
            "the highway near gadshill\n",
            "\n",
            "e\"\n",
            "\n",
            "11 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"\n",
            "\n",
            "\n",
            "scene ii\n",
            "the highway near gadshill\n",
            "\n",
            "e\"\n",
            "\n",
            "11 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 12\n",
            "13592/13592 [==============================] - 559s 41ms/step - loss: 1.4819\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"welcome of a noble foe\n",
            "                 \"\n",
            "\n",
            "12 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"welcome of a noble foe\n",
            "                 \"\n",
            "\n",
            "12 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"welcome of a noble foe\n",
            "                 \"\n",
            "\n",
            "12 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 13\n",
            "13592/13592 [==============================] - 569s 42ms/step - loss: 1.4605\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"sguisd and why not i\n",
            "  lieutenant but jo\"\n",
            "\n",
            "13 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"sguisd and why not i\n",
            "  lieutenant but jo\"\n",
            "\n",
            "13 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"sguisd and why not i\n",
            "  lieutenant but jo\"\n",
            "\n",
            "13 Round completed  model training is completed \n",
            "----------------------------------------\n",
            "Iteration 14\n",
            "13592/13592 [==============================] - 560s 41ms/step - loss: 1.4595\n",
            "n----- diversity: 0.2\n",
            "----- Generating with seed: \"ing queen gloucester cardinal and suffol\"\n",
            "\n",
            "14 Round completed  model training is completed \n",
            "n----- diversity: 0.7\n",
            "----- Generating with seed: \"ing queen gloucester cardinal and suffol\"\n",
            "\n",
            "14 Round completed  model training is completed \n",
            "n----- diversity: 1.2\n",
            "----- Generating with seed: \"ing queen gloucester cardinal and suffol\"\n",
            "\n",
            "14 Round completed  model training is completed \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "_oaNu5HUxC77"
      },
      "source": [
        "## 2. Load the dataset\n",
        "\n",
        "Load the dataset of William Shakespeare’s dataset is used to train the network for automated text generation. Data can be downloaded from http:// www.gutenberg.org/ for the raw file used for training:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM_G9i1C8IsZ"
      },
      "source": [
        "Before training the model, various preprocessing steps are involved to make it work. The following are the major steps involved:\n",
        " \n",
        "\n",
        "*   **Preprocessing:**  Prepare X and Y data from the given entire story text file and converting them into indices vectorized format.\n",
        "*   **Deep learning model training and validation:** Train and validate the deep learning model.\n",
        "*   **Text generation:** Generate the text with the trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9dbd8bc9-fb61-43b9-b0c4-98bd7f3f8150",
        "_uuid": "fda5d4868631d3618d4d9a9a863541b2faf121c0",
        "id": "jz9ZlSZIxC7_"
      },
      "source": [
        "## 3. Dataset preparation\n",
        "\n",
        "### 3.1 Dataset cleaning \n",
        "\n",
        "In dataset preparation step, we will first perform text cleaning of the data which includes removal of punctuations and lower casing all the words. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9d83cc08-19ba-4b00-9ca6-dcf5ff39c8af",
        "_uuid": "6fd11859fd71aa5c7ce10bdbbd31c8eb6d1b3118",
        "id": "rsJs5K0OxC8D"
      },
      "source": [
        "### 3.2 Generating Sequence of N-gram Tokens\n",
        "\n",
        "Language modelling requires a sequence input data, as given a sequence (of words/tokens) the aim is the predict next word/token.  \n",
        "\n",
        "The next step is Tokenization. Tokenization is a process of extracting tokens (terms / words) from a corpus. Python’s library Keras has inbuilt model for tokenization which can be used to obtain the tokens and their index in the corpus. After this step, every text document in the dataset is converted into sequence of tokens. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a22c88f5-f2a3-457c-835b-63341e657e3f",
        "_uuid": "f22aa5e0c04620ca5034ab9389322eee543060c6",
        "id": "CfKSOnAUxC8H"
      },
      "source": [
        "In the above output [30, 507], [30, 507, 11], [30, 507, 11, 1] and so on represents the ngram phrases generated from the input data. where every integer corresponds to the index of a particular word in the complete vocabulary of words present in the text. For example\n",
        "\n",
        "**Headline:** i stand  with the shedevils  \n",
        "**Ngrams:** | **Sequence of Tokens**\n",
        "\n",
        "<table>\n",
        "<tr><td>Ngram </td><td> Sequence of Tokens</td></tr>\n",
        "<tr> <td>i stand </td><td> [30, 507] </td></tr>\n",
        "<tr> <td>i stand with </td><td> [30, 507, 11] </td></tr>\n",
        "<tr> <td>i stand with the </td><td> [30, 507, 11, 1] </td></tr>\n",
        "<tr> <td>i stand with the shedevils </td><td> [30, 507, 11, 1, 975] </td></tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "### 3.3 Padding the Sequences and obtain Variables : Predictors and Target\n",
        "\n",
        "Now that we have generated a data-set which contains sequence of tokens, it is possible that different sequences have different lengths. Before starting training the model, we need to pad the sequences and make their lengths equal. We can use pad_sequence function of Kears for this purpose. To input this data into a learning model, we need to create predictors and label. We will create N-grams sequence as predictors and the next word of the N-gram as label. For example:\n",
        "\n",
        "\n",
        "Headline:  they are learning data science\n",
        "\n",
        "<table>\n",
        "<tr><td>PREDICTORS </td> <td>           LABEL </td></tr>\n",
        "<tr><td>they                   </td> <td>  are</td></tr>\n",
        "<tr><td>they are               </td> <td>  learning</td></tr>\n",
        "<tr><td>they are learning      </td> <td>  data</td></tr>\n",
        "<tr><td>they are learning data </td> <td>  science</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8b5d80ff-54a8-4380-8a3c-149be880551d",
        "_uuid": "8b8a64b96011f427c48d5b0819e3e74af604ce43",
        "id": "HOQ_B7gJxC8M"
      },
      "source": [
        "Perfect, now we can obtain the input vector X and the label vector Y which can be used for the training purposes. Recent experiments have shown that recurrent neural networks have shown a good performance in sequence to sequence learning and text data applications. Lets look at them in brief.\n",
        "\n",
        "## 4. LSTMs for Text Generation\n",
        "\n",
        "![](http://www.shivambansal.com/blog/text-lstm/2.png)\n",
        "\n",
        "Unlike Feed-forward neural networks in which activation outputs are propagated only in one direction, the activation outputs from neurons propagate in both directions (from inputs to outputs and from outputs to inputs) in Recurrent Neural Networks. This creates loops in the neural network architecture which acts as a ‘memory state’ of the neurons. This state allows the neurons an ability to remember what have been learned so far.\n",
        "\n",
        "The memory state in RNNs gives an advantage over traditional neural networks but a problem called Vanishing Gradient is associated with them. In this problem, while learning with a large number of layers, it becomes really hard for the network to learn and tune the parameters of the earlier layers. To address this problem, A new type of RNNs called LSTMs (Long Short Term Memory) Models have been developed.\n",
        "\n",
        "LSTMs have an additional state called ‘cell state’ through which the network makes adjustments in the information flow. The advantage of this state is that the model can remember or forget the leanings more selectively. To learn more about LSTMs, here is a great post. Lets architecture a LSTM model in our code. I have added total three layers in the model.\n",
        "\n",
        "1. Input Layer : Takes the sequence of words as input\n",
        "2. LSTM Layer : Computes the output using LSTM units. I have added 100 units in the layer, but this number can be fine tuned later.\n",
        "3. Dropout Layer : A regularisation layer which randomly turns-off the activations of some neurons in the LSTM layer. It helps in preventing over fitting. (Optional Layer)\n",
        "4. Output Layer : Computes the probability of the best possible next word as output\n",
        "\n",
        "We will run this model for total 100 epoochs but it can be experimented further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1826aa1a-cb77-4379-a69d-e9b180945dce",
        "_uuid": "f0b16b471969dbb831cb0024e303341e11b63de4",
        "id": "UsLHtDjVxC8P"
      },
      "source": [
        "Lets train our model now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "61e99cfe-7395-4d61-8d1a-8539103d3db5",
        "_uuid": "448bf43b123060dfe4e27cb9f12889e4fe0ed2a7",
        "id": "CxhPAWsCxC8S"
      },
      "source": [
        "## 5. Generating the text \n",
        "\n",
        "Great, our model architecture is now ready and we can train it using our data. Next lets write the function to predict the next word based on the input words (or seed text). We will first tokenize the seed text, pad the sequences and pass into the trained model to get predicted word. The multiple predicted words can be appended together to get predicted sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e71e56543b7065f115a05e3fd062262b3b94ad46",
        "id": "7QLIbtgtxC8T"
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ea0bddb6-acc6-4592-a2e0-ffc4129a582f",
        "_uuid": "c49bf4ea0e54f3145149e164e243d897f545b84c",
        "id": "EyHIpVTdxC8W"
      },
      "source": [
        "## 6. Some Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e38dd280-093b-4091-b82b-9aa90045b107",
        "_kg_hide-input": true,
        "_uuid": "a21548224c9e661a29e3d369e348aada0599bdc9",
        "id": "JA7FMxZ-xC8Z",
        "outputId": "d63dafe8-47ff-4b18-9d80-3e9102e0722d"
      },
      "source": [
        "print (generate_text(\"united states\", 50\n",
        "                     , model, max_sequence_len))\n",
        "print (generate_text(\"preident trump\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"donald trump\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"india and china\", 40, model, max_sequence_len))\n",
        "print (generate_text(\"new york\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"science and technology\", 30, model, max_sequence_len))\n",
        "print (generate_text(\"Russia\", 30, model, max_sequence_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "United States Ai Is Cheaper Thats Also Bad News A New Authoritarian Era Gun Ones Has Dog A Border Of Gun Violence Is Sex Gerrymandering In In He It Where Ride Beauty Live To Confinement Or Men Says His Blood Blue Food Corruption Age Dynasty Men Raise Become Is Better Young Young\n",
            "Preident Trump Wants A Military Parade\n",
            "Donald Trump Is Hiding To Twist\n",
            "India And China Better Than Food A Real Impact At The New High Map That Witness To Jail Kurds To Help Was You Him Sex De Moon Men Sex First Age Why Balance Sex Russia Sex Vote Sex Fresh Sex European Million Plastic\n",
            "New York Is Finding A Premier\n",
            "Science And Technology In Babies Slogs To Polls Three Spanish Words That Will Help It Become A Better Crossword Solver Student Comments Of The Week In The United Landing Men Young Young Young\n",
            "India The Supreme Court Become The Run For Dreamers On The Ground Patient The Problem Of The Year Plan In Help Away The Barely Poland Corner Of Sex Raises New Athletes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b2cfe563-974a-4e05-ad60-233d409d3de1",
        "_uuid": "279f2e20c482b40d707413d0b1842f179a0d3d7b",
        "id": "TPYKgL9FxC8c"
      },
      "source": [
        "## Improvement Ideas \n",
        "\n",
        "As we can see, the model has produced the output which looks fairly fine. The results can be improved further with following points:\n",
        "- Adding more data\n",
        "- Fine Tuning the network architecture\n",
        "- Fine Tuning the network parameters\n",
        "\n",
        "Thanks for going through the notebook, please upvote if you liked. "
      ]
    }
  ]
}